import React, { useState, useEffect, useRef } from 'react';
import Header from './components/Header';
import InputBar from './components/InputBar';
import MessageBubble from './components/MessageBubble';
import { Message } from './types';
import { INITIAL_MESSAGE } from './constants';
import { analyzeImage } from './services/visionClient';
import { chatWithDeepseekStream } from './services/chatClient';
import { generateDesignImage, uploadImage } from './services/generateClient';
import { compressImage } from './services/utils';

function hasRenderIntent(text: string): boolean {
  const keywords = ['æ•ˆæžœåœ–', 'æ•ˆæžœå›¾', 'å‡ºåœ–', 'å‡ºå›¾', 'æ¸²æŸ“', 'è¨­è¨ˆåœ–', 'è®¾è®¡å›¾', '3dåœ–', '3då›¾', 'æƒ³ç‡ä¸‹', 'æƒ³çœ‹ä¸€ä¸‹'];
  return keywords.some(k => text.includes(k));
}

const App: React.FC = () => {
  // Chat History
  const [messages, setMessages] = useState<Message[]>([INITIAL_MESSAGE]);
  const chatEndRef = useRef<HTMLDivElement>(null);
  
  // State Machine
  const [appState, setAppState] = useState<'IDLE' | 'WAITING_FOR_SPACE' | 'ANALYZING' | 'RENDER_INTAKE' | 'GENERATING_RENDER' | 'REVISION_LOOP'>('IDLE');
  
  // Data Stores
  const [pendingImage, setPendingImage] = useState<{dataUrl: string, blobUrl?: string} | null>(null);
  const [renderData, setRenderData] = useState<{
    space?: string;
    style?: string;
    color?: string;
    requirements?: string;
    step: 'style' | 'color' | 'requirements' | 'ready'; 
  }>({ step: 'style' });
  
  const [lastGeneratedImage, setLastGeneratedImage] = useState<string | null>(null);

  // Scroll to bottom
  const scrollToBottom = () => {
    chatEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // Typewriter Buffer Queue
  const [typewriterBuffer, setTypewriterBuffer] = useState<{msgId: string, queue: string[]} | null>(null);

  // Effect to drain the typewriter buffer
  useEffect(() => {
      if (!typewriterBuffer || typewriterBuffer.queue.length === 0) return;

      const timer = setInterval(() => {
          setTypewriterBuffer(prev => {
              if (!prev || prev.queue.length === 0) return null;
              
              const nextChar = prev.queue[0];
              const remaining = prev.queue.slice(1);
              
              setMessages(currentMessages => currentMessages.map(m => {
                  if (m.id === prev.msgId) {
                      return { ...m, content: m.content + nextChar };
                  }
                  return m;
              }));

              return { ...prev, queue: remaining };
          });
      }, 15); // Fast typing speed

      return () => clearInterval(timer);
  }, [typewriterBuffer]);

  const streamToTypewriter = (msgId: string, chunk: string) => {
      setTypewriterBuffer(prev => {
          const chars = chunk.split('');
          if (prev && prev.msgId === msgId) {
              return { ...prev, queue: [...prev.queue, ...chars] };
          }
          return { msgId, queue: chars };
      });
  };

  // Main Handler
  const handleSendMessage = async (text: string) => {
    // 1. User Message
    const userMsg: Message = {
      id: Date.now().toString(),
      type: 'text',
      content: text,
      sender: 'user',
      timestamp: Date.now()
    };
    setMessages(prev => [...prev, userMsg]);

    // State Machine Logic
    
    // STATE: WAITING_FOR_SPACE
    if (appState === 'WAITING_FOR_SPACE') {
        if (pendingImage) {
            setAppState('ANALYZING');
            await performAnalysisAndSuggestions(pendingImage.dataUrl, pendingImage.blobUrl, text); // text is space name
            setAppState('IDLE');
            return;
        } else {
            setAppState('IDLE');
        }
    }

    // STATE: RENDER_INTAKE
    if (appState === 'RENDER_INTAKE') {
        processRenderIntake(text);
        return;
    }

    // STATE: REVISION_LOOP (Implicit check via Intent)
    if (lastGeneratedImage && (text.includes('å†æ”¹') || text.includes('ä¿®æ”¹') || text.includes('å””ä¿‚å¥½') || text.includes('ä¸å¦‚') || text.includes('è½‰'))) {
        setAppState('REVISION_LOOP');
        await triggerImageGeneration(renderData, pendingImage?.blobUrl, lastGeneratedImage, text);
        setAppState('IDLE');
        return;
    }

    // TRIGGER: RENDER INTAKE
    if (hasRenderIntent(text)) {
        const lastImageMsg = messages.slice().reverse().find(m => m.type === 'image');
        const baseBlobUrl = pendingImage?.blobUrl || (lastImageMsg?.content?.startsWith('http') ? lastImageMsg.content : undefined);

        if (!baseBlobUrl) {
             const reply: Message = {
               id: Date.now().toString() + 'r',
               type: 'text',
               content: 'æƒ³å‡ºæ•ˆæžœåœ–ç„¡å•é¡Œï¼éº»ç…©ä½ ä¸Šè¼‰ä¸€å¼µç¾å ´ç›¸ç‰‡å…ˆï¼Œç­‰æˆ‘å¯ä»¥è·Ÿè¿”å¯¦éš›çµæ§‹åŽ»è¨­è¨ˆã€‚ðŸ“¸',
               sender: 'ai',
               timestamp: Date.now()
             };
             setMessages(prev => [...prev, reply]);
             return;
        }

        if (!pendingImage && baseBlobUrl) {
            setPendingImage({ dataUrl: baseBlobUrl, blobUrl: baseBlobUrl });
        }

        setAppState('RENDER_INTAKE');
        setRenderData({ step: 'style' }); 
        
        const reply: Message = {
            id: Date.now().toString() + 'q1',
            type: 'text',
            content: 'æ”¶åˆ°ï¼æƒ³å¹«ä½ å‡ºå¼µæ•ˆæžœåœ–ã€‚é¦–å…ˆç¢ºèªä¸‹ï¼Œä½ æƒ³è¡Œå’©é¢¨æ ¼ï¼Ÿï¼ˆä¾‹å¦‚ï¼šç¾ä»£ç°¡ç´„/åŒ—æ­/æ—¥ç³»/è¼•å¥¢/å¥¶æ²¹é¢¨ï¼‰',
            sender: 'ai',
            timestamp: Date.now(),
            options: ['ç¾ä»£ç°¡ç´„', 'åŒ—æ­é¢¨', 'æ—¥ç³»æœ¨èª¿', 'è¼•å¥¢é¢¨', 'å¥¶æ²¹é¢¨']
        };
        setMessages(prev => [...prev, reply]);
        return;
    }

    // STATE: IDLE (Normal Chat)
    await performNormalChat(text);
  };

  const performNormalChat = async (text: string) => {
      const aiMsgId = Date.now().toString() + 'ai';
      setMessages(prev => [...prev, {
          id: aiMsgId,
          type: 'text',
          content: '',
          sender: 'ai',
          timestamp: Date.now()
      }]);

      try {
        const history = messages.map(m => ({
            role: m.sender === 'user' ? 'user' as const : 'assistant' as const,
            content: m.content
        }));
        history.push({ role: 'user', content: text });

        for await (const chunk of chatWithDeepseekStream({
            mode: 'consultant',
            text: text,
            messages: history
        })) {
            streamToTypewriter(aiMsgId, chunk);
        }
      } catch (e) {
          console.error(e);
          setMessages(prev => prev.map(m => m.id === aiMsgId ? { ...m, content: 'ç³»çµ±ç¹å¿™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚' } : m));
      }
  };

  const performAnalysisAndSuggestions = async (imageDataUrl: string, imageBlobUrl: string | undefined, spaceType: string) => {
      // 1. Vision Analysis
      const aiMsgId = Date.now().toString() + 'vis';
      setMessages(prev => [...prev, {
          id: aiMsgId,
          type: 'text',
          content: 'æ”¶åˆ°ï¼Œæ­£åœ¨åˆ†æžç©ºé–“çµæ§‹â€¦ ðŸ”', 
          sender: 'ai',
          timestamp: Date.now()
      }]);

      try {
          const visionRes = await analyzeImage({
              imageDataUrl: imageDataUrl,
              imageUrl: imageBlobUrl,
              mode: 'consultant',
              spaceType: spaceType
          } as any);

          if (visionRes.ok && visionRes.vision_summary) {
               setMessages(prev => prev.map(m => m.id === aiMsgId ? { ...m, content: '' } : m));
               
               const prompt = `ç”¨æˆ¶ä¸Šå‚³äº†åœ–ç‰‡ï¼Œç©ºé–“æ˜¯ã€Œ${spaceType}ã€ã€‚è¦–è¦ºåˆ†æžçµæžœï¼š${visionRes.vision_summary}ã€‚è«‹é‡å°æ­¤ç©ºé–“æä¾› 3-4 å€‹é‡å°é¦™æ¸¯ç´°å–®ä½çš„å…·é«”å…¨å±‹è¨‚é€ /æ”¶ç´å»ºè­°ã€‚è«‹ç”¨ç²¾ç°¡ Point Formã€‚`;
               
               for await (const chunk of chatWithDeepseekStream({
                   mode: 'consultant',
                   text: prompt,
                   messages: [],
                   visionSummary: visionRes.vision_summary
               })) {
                   streamToTypewriter(aiMsgId, chunk);
               }

          } else {
              setMessages(prev => prev.map(m => m.id === aiMsgId ? { ...m, content: 'åˆ†æžå¤±æ•—ï¼Œè«‹é‡è©¦ã€‚' } : m));
          }
      } catch (e) {
          console.error(e);
          setMessages(prev => prev.map(m => m.id === aiMsgId ? { ...m, content: 'ç³»çµ±éŒ¯èª¤ï¼Œè«‹é‡è©¦ã€‚' } : m));
      }
  };

  const processRenderIntake = (answer: string) => {
      const nextData = { ...renderData };
      let replyContent = '';
      let options: string[] | undefined;

      switch (renderData.step) {
          case 'style':
              nextData.style = answer;
              nextData.step = 'color';
              replyContent = 'æ˜Žç™½ã€‚è‰²ç³»æ–¹é¢æœ‰ç„¡ç‰¹åˆ¥å–œå¥½ï¼Ÿï¼ˆä¾‹å¦‚ï¼šæ·ºæœ¨/æ·±æœ¨/ç™½/ç°/æš–è‰²ï¼‰';
              options = ['æ·ºæœ¨è‰²', 'æ·±æœ¨è‰²', 'ç™½è‰²ç‚ºä¸»', 'é»‘ç™½ç°', 'æš–ç°è‰²'];
              break;
          case 'color':
              nextData.color = answer;
              nextData.step = 'requirements';
              replyContent = 'æ”¶åˆ°ã€‚æœ€å¾Œï¼Œæœ‰ç„¡å’©æ ¸å¿ƒæ«ƒé«”æˆ–ç‰¹åˆ¥è¦æ±‚ï¼Ÿï¼ˆä¾‹å¦‚ï¼šåˆ°é ‚è¡£æ«ƒ/Cå­—éž‹æ«ƒ/é¿é–‹çª—å°ä½â€¦ï¼‰';
              break;
          case 'requirements':
              nextData.requirements = answer;
              nextData.step = 'ready';
              replyContent = 'è³‡æ–™é½Šå…¨ï¼æˆ‘å¯ä»¥å¹«ä½ ç”Ÿæˆæ•ˆæžœåœ–å–‡ã€‚è«‹ç¢ºèªæ˜¯å¦é–‹å§‹ï¼Ÿ';
              options = ['ç”Ÿæˆæ•ˆæžœåœ–'];
              break;
      }
      
      setRenderData(nextData);
      setMessages(prev => [...prev, {
          id: Date.now().toString(),
          type: 'text',
          content: replyContent,
          sender: 'ai',
          timestamp: Date.now(),
          options
      }]);
  };

  const triggerImageGeneration = async (data: any, baseBlobUrl: string | undefined, lastUrl: string | undefined, revision?: string) => {
      const aiMsgId = Date.now().toString() + 'gen';
      setMessages(prev => [...prev, {
          id: aiMsgId,
          type: 'text',
          content: 'æ”¶åˆ°ï¼Œæˆ‘ä¾å®¶å¹«ä½ è¨­è¨ˆç·Šå¼µæ•ˆæžœåœ–ï¼Œè«‹ç¨ç­‰â€¦ ðŸŽ¨',
          sender: 'ai',
          timestamp: Date.now()
      }]);

      try {
          const payload = {
              prompt: '', 
              renderIntake: { ...data }, 
              baseImageBlobUrl: lastUrl || baseBlobUrl,
              size: '1024x1024'
          };
          
          if (revision && payload.renderIntake) {
              payload.renderIntake.requirements += ` Modification: ${revision}`;
          }

          const res = await generateDesignImage(payload as any);

          if (res.ok && (res.resultBlobUrl || res.b64_json)) {
              const resultUrl = res.resultBlobUrl || (res.b64_json ? `data:image/jpeg;base64,${res.b64_json}` : null);
              
              setMessages(prev => prev.filter(m => m.id !== aiMsgId)); 
              
              setMessages(prev => [...prev, {
                  id: Date.now().toString(),
                  type: 'image',
                  content: resultUrl!,
                  sender: 'ai',
                  timestamp: Date.now()
              }]);
              
              setMessages(prev => [...prev, {
                  id: Date.now().toString() + 'fu',
                  type: 'text',
                  content: 'å‘¢å€‹è¨­è¨ˆä½ è¦ºå¾—é»žï¼Ÿå¦‚æžœæƒ³å¾®èª¿ï¼ˆä¾‹å¦‚è½‰è‰²ã€æ”¹æ«ƒæ¬¾ï¼‰ï¼Œå¯ä»¥ç›´æŽ¥åŒæˆ‘è¬›ã€Œå†æ”¹...ã€ã€‚ðŸ˜Š',
                  sender: 'ai',
                  timestamp: Date.now()
              }]);
              
              setLastGeneratedImage(resultUrl);
          } else {
              throw new Error(res.message);
          }
      } catch (e: any) {
          setMessages(prev => prev.map(m => m.id === aiMsgId ? { 
              ...m, 
              content: `å‡ºåœ–é‡åˆ°å•é¡Œï¼š${e.message || 'è«‹é‡è©¦'}`,
              options: ['é‡è©¦ç”Ÿæˆ']
           } : m));
      }
  };

  const handleSendImage = (file: File) => {
      compressImage(file, 1536, 0.8).then(blob => {
          const reader = new FileReader();
          reader.onload = async (e) => {
              const dataUrl = e.target?.result as string;
              
              setMessages(prev => [...prev, {
                  id: Date.now().toString(),
                  type: 'image',
                  content: dataUrl,
                  sender: 'user',
                  timestamp: Date.now()
              }]);

              let blobUrl = '';
              try {
                  const compressedFile = new File([blob], file.name, { type: 'image/jpeg' });
                  const upRes = await uploadImage(compressedFile);
                  if (upRes?.url) blobUrl = upRes.url;
              } catch (err) {
                  console.error('Upload fail', err);
              }

              setPendingImage({ dataUrl, blobUrl });
              setAppState('WAITING_FOR_SPACE');

              setMessages(prev => [...prev, {
                  id: Date.now().toString() + 'ask',
                  type: 'text',
                  content: 'æ”¶åˆ°ï½žæƒ³ç¢ºèªä¸€ä¸‹ï¼šå‘¢å¼µç›¸ä¿‚é‚Šå€‹ç©ºé–“ï¼Ÿï¼ˆä¾‹å¦‚ï¼šå®¢å»³/ç¡æˆ¿/å»šæˆ¿/çŽ„é—œ/æ›¸æˆ¿/å…¶ä»–ï¼‰',
                  sender: 'ai',
                  timestamp: Date.now()
              }]);
          };
          reader.readAsDataURL(blob);
      });
  };

  const handleOptionClick = (opt: string) => {
      if (opt === 'ç”Ÿæˆæ•ˆæžœåœ–') {
          setAppState('GENERATING_RENDER');
          setMessages(prev => [...prev, {
              id: Date.now().toString(),
              type: 'text',
              content: opt,
              sender: 'user',
              timestamp: Date.now()
          }]);
          triggerImageGeneration(renderData, pendingImage?.blobUrl, undefined);
      } else {
          handleSendMessage(opt);
      }
  };

  return (
    <div className="flex flex-col h-[100dvh] bg-[var(--wa-bg)] overflow-hidden">
      <Header />
      <div className="flex-1 overflow-y-auto px-4 py-1 chat-bg-container relative">
        <div className="flex flex-col gap-1 pb-2 relative z-10">
            {messages.map((msg) => (
                <MessageBubble key={msg.id} message={msg} onOptionClick={handleOptionClick} />
            ))}
            <div ref={chatEndRef} />
        </div>
      </div>
      <InputBar onSendMessage={handleSendMessage} onSendImage={handleSendImage} />
    </div>
  );
};

export default App;
